âœ‹ Hand Gesture Recognition â€” Deep Learning Web App

This project is a Hand Gesture Recognition System that uses a trained Deep Learning model to classify hand gestures from images and a live webcam feed.

The backend is deployed on Render using a TensorFlow Lite model, and the frontend is hosted on GitHub Pages.

ğŸŒ Live Demo

ğŸ”— Website (Frontend UI)
ğŸ‘‰ https://sanil-boop.github.io/gesture-ai-website/

ğŸš€ API (Backend Running on Render)

ğŸ”— Gesture Recognition API
ğŸ‘‰ https://hand-gesture-recognition-3.onrender.com/

ğŸ§  Features

âœ” Upload an image to detect gesture
âœ” Live Webcam prediction
âœ” Confidence percentage bar
âœ” Gesture emoji output
âœ” Prediction history log
âœ” Responsive modern UI
âœ” TensorFlow Lite optimized backend

ğŸ§© Supported Gestures
| Gesture    | Label |
| ---------- | ----- |
| ğŸ– Palm    | palm  |
| âœŠ Fist     | fist  |
| â˜ Index    | index |
| ğŸ‘ Thumb   | thumb |
| ğŸ‘Œ OK      | ok    |
| ğŸ«¸ L-shape | l     |
| â” Blank    | blank |


ğŸ— Tech Stack
ğŸ¯ Frontend

HTML, CSS, JavaScript

Webcam Streaming

Fetch API

ğŸ¤– Backend

Flask

TensorFlow Lite

OpenCV

NumPy

â˜ Deployment

Render (API Hosting)

GitHub Pages (Frontend Hosting)



ğŸ“‚ Project Structure
/Website
 â”œâ”€â”€ index.html
 â”œâ”€â”€ style.css
 â”œâ”€â”€ script.js

Backend
 â”œâ”€â”€ app.py
 â”œâ”€â”€ gesture_model.tflite
 â”œâ”€â”€ label_map.json
 â”œâ”€â”€ requirements.txt
 â”œâ”€â”€ runtime.txt
 â”œâ”€â”€ Procfile

â–¶ Running Locally
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Start Flask server
python app.py


API runs at:

http://127.0.0.1:5000/

ğŸŒ Deployment Overview
Backend (Render)

âœ” Uses tflite-runtime
âœ” Python runtime pinned
âœ” Gunicorn server

Frontend (GitHub Pages)

âœ” Static hosting
âœ” Works with external API
âœ” No framework required

ğŸ§‘â€ğŸ’» Author

ğŸ‘¤ Sanil Maurya
ğŸ“ Pune, Maharashtra
ğŸ“§ sanilmaurya674@gmail.com

ğŸ”— LinkedIn â€” https://www.linkedin.com/in/sanil-maurya-45944a370/
